# Natural_Language_Processing
**[Fall 2024]**

## Overview

| #  | Concept                               | Details                                                                                                                |
|:---:|:-------------------------------------:|:-----------------------------------------------------------------------------------------------------------------------:|
| 1   | **Levels of linguistic Representation & Ambiguity**  |  |
| 2   | **Probability and Machine Learning Basics & Text Classification** | Naive Bayes <br> n-gram language models |
| 3   | **Sequence Labeling & Syntax and Grammar**     | Hidden Markov Models (HMMs) <br> Part-of-Speech (PoS) Tagging & Named-entity recognition  <br> Context-Free Grammars (CFGs) |
| 4   | **Dependency structures**           | PCFGs: CKY <bf> Transition-based Dependency Parsing |
| 5   | **Machine Learning for NLP & Neural Networks**| Log-linear models <br> pyTorch basics |
| 6   | **Vector-based lexical semantics & Pretraining Neural Language Model ** | Distributed representations and words embeddings (word2vec) <br> WordNet and Words Sense Disambiguation |
| 7   | **Recurrent Neural Networks and LSTMs & Contextualized embeddings** | ELMo & Attention |
| 8   | **Transformer based models & Retrieval Augmented Generation** | BERT & GPT |
| 9   | **Sentence-level Semantics & Abstract Meaning Representation**       | Semantic Role Labeling (FrameNet, PropBank) |
| 10  | **Summarization / Machine Translation & Multimodal NLP**       | Language and Vision |
